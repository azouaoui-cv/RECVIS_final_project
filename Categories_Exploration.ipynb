{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchbook\n",
    "\n",
    "* My goal is to understand what is inside the ``.mat`` files from J. Peyre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnRel categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "data_dir = os.path.join(CWD, \"data\")\n",
    "\n",
    "mat = scipy.io.loadmat(os.path.join(data_dir, \"annotated_triplets.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 41 categories\n"
     ]
    }
   ],
   "source": [
    "unrel_categories = list()\n",
    "\n",
    "for arr in mat[\"triplets\"]:\n",
    "    words = arr[0][0].split(\"-\")\n",
    "    for i, word in enumerate(words):\n",
    "        if not word in unrel_categories and i != 1:\n",
    "            unrel_categories.append(word)\n",
    "print(\"There are %d categories\" % len(unrel_categories))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike\n",
      "person\n",
      "building\n",
      "wheel\n",
      "car\n",
      "road\n",
      "tree\n",
      "bus\n",
      "roof\n",
      "elephant\n",
      "cat\n",
      "dog\n",
      "skateboard\n",
      "tie\n",
      "chair\n",
      "cone\n",
      "horse\n",
      "refrigerator\n",
      "motorcycle\n",
      "hat\n",
      "helmet\n",
      "pants\n",
      "shirt\n",
      "shoes\n",
      "sunglasses\n",
      "glasses\n",
      "sofa\n",
      "bed\n",
      "plane\n",
      "cart\n",
      "box\n",
      "traffic light\n",
      "boat\n",
      "giraffe\n",
      "suitcase\n",
      "train\n",
      "bench\n",
      "jacket\n",
      "table\n",
      "truck\n",
      "umbrella\n"
     ]
    }
   ],
   "source": [
    "for category in unrel_categories:\n",
    "    print(category)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COCO Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_categories = [\"person\",\n",
    "                   \"bicycle\", \n",
    "                   \"car\",\n",
    "                   \"motorcycle\",\n",
    "                   \"airplane\",\n",
    "                   \"bus\",\n",
    "                   \"train\",\n",
    "                   \"truck\",\n",
    "                   \"boat\",\n",
    "                   \"traffic light\",\n",
    "                   \"fire hydrant\", \n",
    "                   \"stop sign\", \n",
    "                   \"parking meter\",\n",
    "                   \"bench\",\n",
    "                   \"cat\",\n",
    "                   \"dog\",\n",
    "                   \"horse\",\n",
    "                   \"sheep\",\n",
    "                   \"cow\", \n",
    "                   \"elephant\",\n",
    "                   \"bear\",\n",
    "                   \"zebra\",\n",
    "                   \"giraffe\",\n",
    "                   \"backpack\",\n",
    "                   \"umbrella\",\n",
    "                   \"handbag\",\n",
    "                   \"tie\", \n",
    "                   \"suitcase\",\n",
    "                   \"frisbee\",\n",
    "                   \"skis\",\n",
    "                   \"snowboard\",\n",
    "                   \"sports ball\",\n",
    "                   \"kite\",\n",
    "                   \"baseball bat\",\n",
    "                   \"baseball glove\",\n",
    "                   \"skateboard\", \n",
    "                   \"surfboard\",\n",
    "                   \"tennis racket\",\n",
    "                   \"bottle\",\n",
    "                   \"wine glass\",\n",
    "                   \"cup\",\n",
    "                   \"fork\",\n",
    "                   \"knife\",\n",
    "                   \"spoon\",\n",
    "                   \"bowl\",\n",
    "                   \"banana\",\n",
    "                   \"apple\",\n",
    "                   \"sandwich\",\n",
    "                   \"orange\",\n",
    "                   \"broccoli\",\n",
    "                   \"carrot\",\n",
    "                   \"hot dog\",\n",
    "                   \"pizza\",\n",
    "                   \"donut\",\n",
    "                   \"cake\",\n",
    "                   \"bird\",\n",
    "                   \"chair\",\n",
    "                   \"couch\",\n",
    "                   \"potted plant\",\n",
    "                   \"bed\",\n",
    "                   \"dining table\",\n",
    "                   \"toilet\",\n",
    "                   \"tv\",\n",
    "                   \"laptop\",\n",
    "                   \"mouse\",\n",
    "                   \"remote\",\n",
    "                   \"keyboard\",\n",
    "                   \"cell phone\",\n",
    "                   \"sink\",\n",
    "                   \"refrigerator\",\n",
    "                   \"book\",\n",
    "                   \"clock\",\n",
    "                   \"vase\",\n",
    "                   \"scissors\",\n",
    "                   \"teddy bear\",\n",
    "                   \"hair drier\",\n",
    "                   \"toothbrush\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bike\n",
      "building\n",
      "wheel\n",
      "road\n",
      "tree\n",
      "roof\n",
      "cone\n",
      "hat\n",
      "helmet\n",
      "pants\n",
      "shirt\n",
      "shoes\n",
      "sunglasses\n",
      "glasses\n",
      "sofa\n",
      "plane\n",
      "cart\n",
      "box\n",
      "jacket\n",
      "table\n"
     ]
    }
   ],
   "source": [
    "for word in unrel_categories:\n",
    "    if not word in coco_categories:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "* There are 20 missing categories from the base class names in COCO."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* bike = bicycle\n",
    "* building?\n",
    "* wheel?\n",
    "* road?\n",
    "* tree? (but present in textual words in figure 6)\n",
    "* roof?\n",
    "* cone?\n",
    "* cap?\n",
    "* helmet?\n",
    "* pants?\n",
    "* shirt?\n",
    "* shoes?\n",
    "* sunglasses?\n",
    "* sofa = (couch => sofa)\n",
    "* plane = (airplane => airplane)\n",
    "* cart?\n",
    "* box?\n",
    "* jacket?\n",
    "* table = (dining table => table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flickr30k categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "flickr30k_class_names_file = os.path.join(CWD, \"NBT\", \"data\", \"flickr30k\", \"flickr30k_class_name.txt\")\n",
    "flickr30k_class_names = list()\n",
    "with open(flickr30k_class_names_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        flickr30k_class_names.append(line.split('\\n')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "elephant\n",
      "refrigerator\n",
      "shoes\n",
      "sunglasses\n",
      "glasses\n",
      "sofa\n",
      "traffic light\n",
      "giraffe\n",
      "suitcase\n"
     ]
    }
   ],
   "source": [
    "for word in unrel_categories:\n",
    "    if not word in flickr30k_class_names:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* There are only 9 categories (out of 41) missing in the Flickr30k categories.\n",
    "\n",
    "* We need a custom mapping from ``UnRel`` categories to ``Flickr30k`` categories. We propose the following:\n",
    "\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "It is arguably easier to build on the Flickr30k vocabulary to produce captions on the UnRel dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finer analysis using COCO dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/inzouzouwetrust/MVA/Cours_S1/RECVIS/RECVIS_final_project'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CWD = os.getcwd()\n",
    "CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_dic_path = os.path.join(CWD, \"NBT\", \"data\", \"coco\", \"dic_coco.json\")\n",
    "with open(COCO_dic_path, \"r\") as f:\n",
    "    COCO_dic = json.load(f, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "COCO_categories = list(COCO_dic[\"wtod\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building\n",
      "wheel\n",
      "road\n",
      "tree\n",
      "roof\n",
      "cone\n",
      "hat\n",
      "helmet\n",
      "pants\n",
      "shirt\n",
      "shoes\n",
      "sunglasses\n",
      "glasses\n",
      "cart\n",
      "box\n",
      "jacket\n"
     ]
    }
   ],
   "source": [
    "for word in unrel_categories:\n",
    "    if not word in COCO_categories:\n",
    "        print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* There are still 16 categories missing (compared to 9 when using ``Flickr30k``)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UnRel GT proposals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy.io\n",
    "import h5py\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CWD = os.getcwd()\n",
    "data_dir = os.path.join(CWD, \"data\")\n",
    "\n",
    "mat = scipy.io.loadmat(os.path.join(data_dir, \"annotations.mat\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([array([[(array([u'1.jpg'], dtype='<U5'), array([[1]], dtype=uint8), array([[array([[(array([u'bike'], dtype='<U4'), array([u'person'], dtype='<U6'), array([[ 716,  111, 1197,  457]], dtype=uint16), array([[ 760,  342, 1042, 1037]], dtype=uint16), array([[array([u'above'], dtype='<U5')]], dtype=object))]],\n",
       "      dtype=[('sub', 'O'), ('obj', 'O'), ('sub_box', 'O'), ('obj_box', 'O'), ('rels', 'O')])]],\n",
       "      dtype=object), array([[array([[(array([u'person'], dtype='<U6'), array([[ 760,  342, 1042, 1037]], dtype=uint16))]],\n",
       "      dtype=[('category', 'O'), ('box', 'O')])],\n",
       "       [array([[(array([u'bike'], dtype='<U4'), array([[ 716,  111, 1197,  457]], dtype=uint16))]],\n",
       "      dtype=[('category', 'O'), ('box', 'O')])]], dtype=object))]],\n",
       "      dtype=[('filename', 'O'), ('im_id', 'O'), ('relationships', 'O'), ('objects', 'O')])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"annotations\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 760,  342, 1042, 1037]], dtype=uint16)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(mat[\"annotations\"][0][0][0][0][-1][0][0][0][0][1].shape)\n",
    "mat[\"annotations\"][0][0][0][0][-1][0][0][0][0][1] # first BB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 716,  111, 1197,  457]], dtype=uint16)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat[\"annotations\"][0][0][0][0][-1][1][0][0][0][1] # second BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* UnRel bounding boxes format: (``bottom_left_corner_x``, ``bottom_left_corner_y``, ``top_right_corner_x``, ``top_right_corner_y``)\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* Create dictionary with fields ``id`` and ``proposals`` => I do not need an ``id`` field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* All the images are there!\n",
    "\n",
    "**TODO**: Check if there can be more than 2 proposals per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mat[\"annotations\"][0][0][0][0][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 14, 15, 16, 19]),\n",
       " array([558, 243, 125,  53,  39,  22,  15,   6,   1,   2,   1,   2,   2,\n",
       "          1,   1]))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_proposals = list()\n",
    "for i, row in enumerate(mat[\"annotations\"]):\n",
    "    n_proposals.append(len(row[0][0][0][-1]))\n",
    "np.unique(n_proposals, return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* There can be as many as 20 GT bounding boxes!\n",
    "\n",
    "**TODO:**\n",
    "\n",
    "* I want to create a nd-array of size (``n_images``, ``n_max_proposals``, ``n_coordinates``)\n",
    "\n",
    "* From what we see above, we have:\n",
    "  * ``n_images``: 1071\n",
    "  * ``n_max_proposals``: 19 (let us make it 20)\n",
    "  * ``n_coordinates``: 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images = len(mat[\"annotations\"])\n",
    "n_max_proposals = max(np.unique(n_proposals)) + 1\n",
    "n_coordinates = 4\n",
    "\n",
    "proposals_array = np.zeros((n_images, n_max_proposals, n_coordinates)) # Let it cast the coordinates as float\n",
    "num_proposals_array = np.zeros((n_images,))\n",
    "\n",
    "for i, row in enumerate(mat[\"annotations\"]):\n",
    "    gt_boxes = row[0][0][0][-1]\n",
    "    num_proposals = len(gt_boxes)\n",
    "    num_proposals_array[i] = num_proposals\n",
    "    for j in range(num_proposals):\n",
    "        proposals_array[i, j, :] = gt_boxes[j][0][0][0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2., 2., 2., 4., 2.])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_proposals_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[7.600e+02, 3.420e+02, 1.042e+03, 1.037e+03],\n",
       "        [7.160e+02, 1.110e+02, 1.197e+03, 4.570e+02],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[6.100e+02, 5.340e+02, 8.880e+02, 1.000e+03],\n",
       "        [3.830e+02, 3.550e+02, 8.030e+02, 7.100e+02],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[2.310e+02, 1.180e+02, 5.280e+02, 9.600e+02],\n",
       "        [1.000e+00, 1.000e+00, 6.710e+02, 6.120e+02],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[2.290e+02, 1.310e+02, 3.180e+02, 2.760e+02],\n",
       "        [2.050e+02, 7.900e+01, 3.690e+02, 1.890e+02],\n",
       "        [3.680e+02, 1.300e+02, 4.350e+02, 2.850e+02],\n",
       "        [4.050e+02, 1.930e+02, 4.770e+02, 3.010e+02],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]],\n",
       "\n",
       "       [[3.520e+02, 1.380e+02, 5.230e+02, 4.980e+02],\n",
       "        [2.850e+02, 4.600e+01, 5.890e+02, 2.310e+02],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00],\n",
       "        [0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proposals_array[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "unrel_proposals_path = os.path.join(CWD, \"data\", \"unrel_proposals_gt.h5\")\n",
    "with h5py.File(unrel_proposals_path, \"w\", driver=\"core\") as f:\n",
    "    f.create_dataset(\"proposals\", data=proposals_array)\n",
    "    f.create_dataset(\"num_proposals\", data=num_proposals_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1071, 20, 4)\n"
     ]
    }
   ],
   "source": [
    "with h5py.File(unrel_proposals_path, \"r\", driver=\"core\") as f:\n",
    "    keys = f.keys()\n",
    "    proposals = f[\"proposals\"][:]\n",
    "    num_proposals = f[\"num_proposals\"][:]\n",
    "print(proposals.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Updating the proposals\n",
    "\n",
    "* These proposals above do not respect what is expected from the NBT model.\n",
    "\n",
    "The NBT model expects the following format: (``n_images``, ``n_max_proposals``, (``x_min``, ``y_min``, ``x_max``, ``y_max``, ``detection_index``, ``confidence``))\n",
    "\n",
    "* Instead of using the Ground Truth proposals from UnRel, we use the candidates found by [Weakly-supervised learning for visual relations](https://www.di.ens.fr/willow/research/unrel/) that can be found [here](http://www.di.ens.fr/willow/research/unrel/release/preproc_data.zip) => This is too complicated for now...\n",
    "\n",
    "* We also want to map the categories from UnRel to categories in Flickr30k to enable us to reuse Flickr30k vocabulary. First of all, we have a good overlap since there is only 9 categories from UnRel that are missing in Flickr30k. The goal is to map the missing UnRel categories to categories in Flickr30k. This part has to be done manually.\n",
    "\n",
    "* Note that we also need the detection index, hence we will load ``dic_unrel.json`` to retrieve such index.\n",
    "\n",
    "* We might need the real detection confidence that can be found in the candidates data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ``dic_unrel.json`` and get the wtod and dtow dictionaries\n",
    "import json\n",
    "import numpy as np\n",
    "import h5py\n",
    "import os\n",
    "import scipy.io\n",
    "\n",
    "CWD = os.getcwd()\n",
    "\n",
    "dic_unrel_path = os.path.join(CWD, \"data\", \"dic_unrel.json\")\n",
    "\n",
    "with open(dic_unrel_path, \"r\") as f:\n",
    "    dic_unrel = json.load(f, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "wtod = dic_unrel[\"wtod\"]\n",
    "dtow = {value: key for key, value in wtod.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remapping:**\n",
    "\n",
    "* elephant => animal\n",
    "* refrigerator => booth?\n",
    "* shoes => shoe\n",
    "* sunglasses => sunglass\n",
    "* sofa => couch\n",
    "* traffic light => light\n",
    "* giraffe => animal\n",
    "* suitcase => bag?\n",
    "* glasses => glass\n",
    "* trees => tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remapping\n",
    "remapping = {\"elephant\": \"animal\",\n",
    "             \"refrigerator\": \"other\",\n",
    "             \"shoes\": \"shoe\",\n",
    "             \"sunglasses\": \"sunglass\",\n",
    "             \"sofa\": \"couch\",\n",
    "             \"traffic light\": \"light\",\n",
    "             \"giraffe\": \"animal\",\n",
    "             \"suitcase\": \"bag\",\n",
    "             \"glasses\": \"glass\",\n",
    "             \"trees\": \"tree\",\n",
    "             \"glasses\": \"goggles\",\n",
    "             \"watch\": \"other\"}\n",
    "# Add missing categories in wtod\n",
    "for cat in remapping.keys():\n",
    "    wtod[cat] = wtod[remapping[cat]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reformat proposals\n",
    "CWD = os.getcwd()\n",
    "annotations_path = os.path.join(CWD, \"data\", \"annotations.mat\")\n",
    "\n",
    "mat = scipy.io.loadmat(annotations_path)\n",
    "\n",
    "\n",
    "n_proposals = list()\n",
    "for i, row in enumerate(mat[\"annotations\"]):\n",
    "    n_proposals.append(len(row[0][0][0][-1]))\n",
    "np.unique(n_proposals, return_counts=True)\n",
    "\n",
    "#n_images = len(mat[\"annotations\"])\n",
    "n_images = 1197\n",
    "n_max_proposals = max(np.unique(n_proposals)) + 1\n",
    "n_dimensions = 6\n",
    "\n",
    "proposals_array = np.zeros((n_images, n_max_proposals, n_dimensions)) # Let it cast the coordinates as float\n",
    "num_proposals_array = np.zeros((n_images,))\n",
    "\n",
    "# TODO: Populate confidence\n",
    "proposals_array[:, :, -1] = 1.0\n",
    "\n",
    "for i, row in enumerate(mat[\"annotations\"]):\n",
    "    gt_boxes = row[0][0][0][-1]\n",
    "    img_id = int(row[0][0][0][0][0].split(\".\")[0])\n",
    "    num_proposals = len(gt_boxes)\n",
    "    num_proposals_array[img_id] = num_proposals\n",
    "    for j in range(num_proposals):\n",
    "        proposals_array[img_id, j, :4] = gt_boxes[j][0][0][0][1]\n",
    "        category = gt_boxes[j][0][0][0][0][0]\n",
    "        proposals_array[img_id, j, 4] = wtod[category] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save proposals\n",
    "unrel_proposals_path = os.path.join(CWD, \"data\", \"unrel_proposals_gt.h5\")\n",
    "with h5py.File(unrel_proposals_path, \"w\", driver=\"core\") as f:\n",
    "    f.create_dataset(\"proposals\", data=proposals_array)\n",
    "    f.create_dataset(\"num_proposals\", data=num_proposals_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1197, 20, 6)\n"
     ]
    }
   ],
   "source": [
    "# Load proposals to check\n",
    "with h5py.File(unrel_proposals_path, \"r\", driver=\"core\") as f:\n",
    "    keys = f.keys()\n",
    "    proposals = f[\"proposals\"][:]\n",
    "    num_proposals = f[\"num_proposals\"][:]\n",
    "print(proposals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recvisp2",
   "language": "python",
   "name": "recvisp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
