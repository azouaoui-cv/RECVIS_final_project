{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flickr30k dataset exploration\n",
    "\n",
    "* This notebook will help us understand what is needed in order to produce captions on the UnRel dataset by investigating how captions are generated on the Flickr30k dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/inzouzouwetrust/MVA/Cours_S1/RECVIS/RECVIS_final_project'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CWD = os.getcwd()\n",
    "CWD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = os.path.join(CWD, \"NBT\", \"data\", \"flickr30k\", \"dataset_flickr30k.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(dataset_filename, \"r\") as f:\n",
    "    dataset = json.load(f, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "splits = {}\n",
    "\n",
    "for img in dataset[\"images\"]:\n",
    "    if splits.get(img[\"split\"]):\n",
    "        splits[img[\"split\"]] += 1\n",
    "    else:\n",
    "        splits[img[\"split\"]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'test': 1000, u'train': 29000, u'val': 1014}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Comment:**\n",
    "\n",
    "* My remark about how only the \"val\" split was used in NBT might be invalid. At least there is a \"test\" split in the original splits by Karpathy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset_unrel.json\n",
    "\n",
    "* My goal now is to apply some preprocessing to the UnRel captions that we produced in order to generate a file that looks like the original \"dataset_flickr30k.json\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = {\"dataset\": \"UnRel\",\n",
    "        \"images\": list()}\n",
    "\n",
    "unrel_dataset_filename = os.path.join(CWD, \"data\", \"unrelcropped.csv\")\n",
    "with open(unrel_dataset_filename, \"r\") as f:\n",
    "    reader = csv.reader(f, delimiter=\",\", )\n",
    "    for i, row in enumerate(reader):\n",
    "        if i == 0: # Header information\n",
    "            continue\n",
    "            \n",
    "        filename = row[0]\n",
    "        sent1 = row[1]\n",
    "        sent1id = int(row[2])\n",
    "        sent2 = row[3]\n",
    "        sent2id = int(row[4])\n",
    "        sent3 = row[5]\n",
    "        sent3id = int(row[6])\n",
    "        imgid = int(filename.split(\".\")[0])\n",
    "        \n",
    "        #sent1_tokens = {}\n",
    "        #for i, word in enumerate(sent1.split(\" \")):\n",
    "        #    sent1_tokens[i] = word.strip(\".\")\n",
    "        \n",
    "        sentences = list()\n",
    "        for tup in [(sent1, sent1id), (sent2, sent2id), (sent3, sent3id)]:\n",
    "            sent, sentid = tup\n",
    "            tokens = {i: word.strip(\".\") for i, word in enumerate(sent.split(\" \"))}\n",
    "            sentences.append({\"tokens\": tokens,\n",
    "                              \"raw\": sent,\n",
    "                              \"imgid\": imgid,\n",
    "                              \"sentid\": sentid})\n",
    "        \n",
    "        # TODO: Build sub dictionary in images list\n",
    "        tmp = {\"sentids\": [sent1id, sent2id, sent3id],\n",
    "               \"imgid\": imgid,\n",
    "               \"split\": \"test\",\n",
    "               \"filename\": filename,\n",
    "               \"sentences\": sentences}\n",
    "        \n",
    "        # TODO: Append dictionary in images list\n",
    "        root[\"images\"].append(tmp)\n",
    "        \n",
    "# Dump the json\n",
    "with open(os.path.join(CWD, \"data\", \"dataset_unrel.json\"), \"w\") as f:\n",
    "    json.dump(root, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## cap_unrel.json\n",
    "\n",
    "* We do it the **COCO** way. The dictionary ``root`` is a list of a list of *captions* that are in the form of a sequence of *tokens*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = os.path.join(CWD, \"data\", \"dataset_unrel.json\")\n",
    "caption_filename = os.path.join(CWD, \"data\", \"cap_unrel.json\")\n",
    "\n",
    "with open(dataset_filename, \"r\") as f:\n",
    "    dataset = json.load(f, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Annotated images in UnRel: ', 115)\n",
      "('Number of captions per image: ', 3)\n"
     ]
    }
   ],
   "source": [
    "n_images = len(dataset[\"images\"])\n",
    "n_captions = 3\n",
    "print(\"Annotated images in UnRel: \", n_images)\n",
    "print(\"Number of captions per image: \", n_captions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = list()\n",
    "\n",
    "for i, image in enumerate(dataset[\"images\"]):\n",
    "    sentences = list()\n",
    "    for j, sentence in enumerate(image[\"sentences\"]):\n",
    "        sentences.append(sentence[\"tokens\"])\n",
    "    root.append(sentences)\n",
    "    \n",
    "with open(caption_filename, \"w\") as f:\n",
    "    json.dump(root, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dic_unrel.json\n",
    "\n",
    "* We do it the **COCO** way but using **Flickr30k** vocabulary since there is a greater overlap (see Categories_Exploration notebook).\n",
    "\n",
    "* We only wish to modify the ``images`` field in ``dic_flickr30k.json`` to populate it with the **UnRel** images instead. We save the result as ``dic_unrel.json``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_filename = os.path.join(CWD, \"data\", \"dataset_unrel.json\")\n",
    "flickr30k_dic_filename = os.path.join(CWD, \"NBT\", \"data\", \"flickr30k\", \"dic_flickr30k.json\")\n",
    "unrel_dic_filename = os.path.join(CWD, \"data\", \"dic_unrel.json\")\n",
    "\n",
    "with open(dataset_filename, \"r\") as f:\n",
    "    dataset = json.load(f, encoding=\"utf-8\")\n",
    "    \n",
    "with open(flickr30k_dic_filename, \"r\") as f:\n",
    "    flickr30k_dic = json.load(f, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'sentids', u'imgid', u'sentences', u'split', u'filename']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[\"images\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'file_path', u'id', u'split']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flickr30k_dic[\"images\"][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dictionary\n",
    "unrel_dic = dict(flickr30k_dic)\n",
    "\n",
    "# Build a list of images to replace the current flickr30k_dic field\n",
    "images = list()\n",
    "for i, image in enumerate(dataset[\"images\"]):\n",
    "    images.append({\"file_path\": image[\"filename\"],\n",
    "                   \"id\": image[\"imgid\"],\n",
    "                   \"split\": image[\"split\"]})\n",
    "unrel_dic[\"images\"] = images\n",
    "\n",
    "# Save UnRel dictionary\n",
    "with open(unrel_dic_filename, \"w\") as f:\n",
    "    json.dump(unrel_dic, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now is time to modify the source code to introduce the UnRel dataset\n",
    "\n",
    "* Here we keep track of the changes we have made so far:\n",
    "  * ``demo.py`` => ``demo_unrel.py``\n",
    "    * Remove ``bboxs`` and ``masks`` in demo code (not used anyway)\n",
    "  * ``main.py`` => ``main_unrel.py``\n",
    "  * ``dataloader_flickr30k.py`` => ``dataloader_unrel.py``\n",
    "    * Add ``utils.RandomCrop``\n",
    "    * Rewrite the proposals h5 file loading part\n",
    "    * Get rid of useless ``gt_seq``, ``gt_bboxes``, ``mask``, ``input_seq``...\n",
    "  * ``utils.RandomCropWithBbox`` => ``utils.RandomCrop``\n",
    "    * Remove the ``bboxs`` component in the random crop\n",
    "    \n",
    "* Next step, try ``demo_unrel.py``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Current progress:**\n",
    "\n",
    "* The proposals I am using only contain the "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language evaluation .json file\n",
    "\n",
    "* This section aims to create a .json file similar to ``caption_flickr30k.json`` found in ``tools/coco-caption/pycocotools/annotations`` so that the language evaluation can be conducted.\n",
    "\n",
    "* The expected file format is as follow: ``root = {\"images\": [{\"file_name\": ..., \"id\": ...}, ... ] (duplicated images), \"info\": None, \"licenses\": None, \"type\": \"captions\", \"annotations\": [{\"image_id\", \"id\", \"caption\" (raw)}, ...]}``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "CWD = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(CWD, \"data\", \"dataset_unrel.json\"), \"r\") as f:\n",
    "    dataset = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'images', u'dataset']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = {\"images\": list(),\n",
    "        \"info\": None,\n",
    "        \"licenses\": None,\n",
    "        \"type\": \"captions\",\n",
    "        \"annotations\": list()}\n",
    "\n",
    "sent_id = 0\n",
    "img_id = 0\n",
    "for i, image in enumerate(dataset[\"images\"]):\n",
    "    for j, sent in enumerate(image[\"sentences\"]):\n",
    "        root[\"images\"].append({\"file_name\": image[\"filename\"],\n",
    "                               \"id\": image[\"imgid\"]})\n",
    "        root[\"annotations\"].append({\"image_id\": image[\"imgid\"],\n",
    "                                    \"id\": sent[\"sentid\"],\n",
    "                                    \"caption\": sent[\"raw\"]})\n",
    "        \n",
    "# Dump the json\n",
    "with open(os.path.join(CWD, \"NBT\", \"tools\", \"coco-caption\", \"annotations\", \"caption_unrel.json\"), \"w\") as f:\n",
    "    json.dump(root, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recvisp2",
   "language": "python",
   "name": "recvisp2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
